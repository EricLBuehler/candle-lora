searchState.loadedDescShard("candle_lora", 0, "Any layer that is conv1d-like.\nAny layer that is conv2d-like.\nAny layer that is embedding-like.\nA value of type <code>L</code>.\nAny layer that is linear-like.\nConfiguration for LoraConv1d. Other configurations are …\nConfiguration for LoraConv2d. Other configurations are …\nConfiguration for LoraEmbedding, with <code>num_embeddings</code> …\nConfiguration for LoraLinear\nNew layers, after conversion\nA value of type <code>R</code>.\nConvert the selected layers into their LoRA counterparts.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nGet the delta weight of the LoRA layer. This is meant to …\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nMerge the LoRA weights.\nCreate a new LoRA config.\nUnmerge the LoRA weights.")
var searchIndex = new Map(JSON.parse('[\
["candle_lora",{"doc":"","t":"PKKKPKFFFFFFFFFFKGIFPPKFFNNNNMMMNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNMMNNOONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNOMNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNMNNNNMNNNNMNNNNNNNNNNNNNNNNNNNNNNNNNNNNNOMNNNNNNNNNNNNNNMNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNMNNNNNNNNNNNNNNNNNNMMMNNN","n":["AlreadyMerged","Conv1dLayerLike","Conv2dLayerLike","EmbeddingLayerLike","Left","LinearLayerLike","Lora","LoraConfig","LoraConv1d","LoraConv1dConfig","LoraConv2d","LoraConv2dConfig","LoraEmbedding","LoraEmbeddingConfig","LoraLinear","LoraLinearConfig","Merge","MergeError","MergeErrorOrError","NewLayers","NotMerged","Right","Saveable","SelectedLayers","SelectedLayersBuilder","add_conv1d_layers","add_conv2d_layers","add_embed_layers","add_linear_layers","bias","bias","bias","bias","bias","bias","borrow","borrow","borrow","borrow","borrow","borrow","borrow","borrow","borrow","borrow","borrow","borrow","borrow","borrow","borrow_mut","borrow_mut","borrow_mut","borrow_mut","borrow_mut","borrow_mut","borrow_mut","borrow_mut","borrow_mut","borrow_mut","borrow_mut","borrow_mut","borrow_mut","borrow_mut","build","clone","clone","clone","clone","clone","clone","clone","clone","clone","clone_into","clone_into","clone_into","clone_into","clone_into","clone_into","clone_into","clone_into","clone_into","config","config","config","config","conv1d","conv2d","convert_model","default","deref","deref","deref","deref","deref","deref","deref","deref","deref","deref","deref","deref","deref","deref","deref_mut","deref_mut","deref_mut","deref_mut","deref_mut","deref_mut","deref_mut","deref_mut","deref_mut","deref_mut","deref_mut","deref_mut","deref_mut","deref_mut","drop","drop","drop","drop","drop","drop","drop","drop","drop","drop","drop","drop","drop","drop","embed","embeddings","embeddings","eq","fmt","fmt","fmt","fmt","fmt","fmt","fmt","fmt","fmt","fmt","fmt","forward","forward","forward","forward","forward_t","forward_t","forward_t","forward_t","from","from","from","from","from","from","from","from","from","from","from","from","from","from","get_delta_weight","get_delta_weight","get_delta_weight","get_delta_weight","get_delta_weight","get_tensors","get_tensors","get_tensors","get_tensors","get_tensors","hidden_size","hidden_size","init","init","init","init","init","init","init","init","init","init","init","init","init","init","into","into","into","into","into","into","into","into","into","into","into","into","into","into","linear","merge_weights","merge_weights","merge_weights","merge_weights","merge_weights","new","new","new","new","new","new","new","new","new","new","shape","shape","to_owned","to_owned","to_owned","to_owned","to_owned","to_owned","to_owned","to_owned","to_owned","to_string","try_from","try_from","try_from","try_from","try_from","try_from","try_from","try_from","try_from","try_from","try_from","try_from","try_from","try_from","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","try_into","type_id","type_id","type_id","type_id","type_id","type_id","type_id","type_id","type_id","type_id","type_id","type_id","type_id","type_id","unmerge_weights","unmerge_weights","unmerge_weights","unmerge_weights","unmerge_weights","vzip","vzip","vzip","vzip","vzip","vzip","vzip","vzip","vzip","vzip","vzip","vzip","vzip","vzip","weight","weight","weight","weight","weight","weight"],"q":[[0,"candle_lora"],[304,"std::collections::hash::map"],[305,"core::cmp"],[306,"core::cmp"],[307,"candle_core::tensor"],[308,"core::option"],[309,"candle_nn::conv"],[310,"candle_nn::conv"],[311,"core::fmt"],[312,"core::fmt"],[313,"candle_core::error"],[314,"alloc::string"],[315,"candle_core::shape"],[316,"core::any"]],"d":["","Any layer that is conv1d-like.","Any layer that is conv2d-like.","Any layer that is embedding-like.","A value of type <code>L</code>.","Any layer that is linear-like.","","","","Configuration for LoraConv1d. Other configurations are …","","Configuration for LoraConv2d. Other configurations are …","","Configuration for LoraEmbedding, with <code>num_embeddings</code> …","","Configuration for LoraLinear","","","","New layers, after conversion","","A value of type <code>R</code>.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Convert the selected layers into their LoRA counterparts.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Returns the argument unchanged.","Returns the argument unchanged.","Returns the argument unchanged.","Returns the argument unchanged.","Returns the argument unchanged.","Returns the argument unchanged.","Returns the argument unchanged.","Returns the argument unchanged.","Returns the argument unchanged.","Returns the argument unchanged.","Returns the argument unchanged.","Returns the argument unchanged.","Returns the argument unchanged.","Returns the argument unchanged.","Get the delta weight of the LoRA layer. This is meant to …","","","","","","","","","","","","","","","","","","","","","","","","","","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","","Merge the LoRA weights.","","","","","","","","","","","","","","Create a new LoRA config.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Unmerge the LoRA weights.","","","","","","","","","","","","","","","","","","","","","","","",""],"i":[28,0,0,0,36,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,28,36,0,0,0,1,1,1,1,12,2,8,16,17,18,43,19,1,26,16,4,17,9,20,11,18,13,21,28,43,19,1,26,16,4,17,9,20,11,18,13,21,28,1,16,4,17,9,20,11,18,13,21,16,4,17,9,20,11,18,13,21,2,8,16,17,26,26,43,1,43,19,1,26,16,4,17,9,20,11,18,13,21,28,43,19,1,26,16,4,17,9,20,11,18,13,21,28,43,19,1,26,16,4,17,9,20,11,18,13,21,28,26,10,20,28,16,4,17,9,20,11,18,13,21,28,28,16,17,20,18,16,17,20,18,43,19,1,26,16,4,17,9,20,11,18,13,21,28,35,16,17,20,18,37,16,17,20,18,10,20,43,19,1,26,16,4,17,9,20,11,18,13,21,28,43,19,1,26,16,4,17,9,20,11,18,13,21,28,26,35,16,17,20,18,1,16,4,17,9,20,11,18,13,21,12,18,16,4,17,9,20,11,18,13,21,28,43,19,1,26,16,4,17,9,20,11,18,13,21,28,43,19,1,26,16,4,17,9,20,11,18,13,21,28,43,19,1,26,16,4,17,9,20,11,18,13,21,28,35,16,17,20,18,43,19,1,26,16,4,17,9,20,11,18,13,21,28,12,2,8,16,17,18],"f":"`````````````````````````{{{b{c}}{f{cd}}h}{{b{c}}}{jln}}{{{b{c}}{f{cA`}}Ab}{{b{c}}}{jln}}{{{b{c}}{f{cAd}}Af}{{b{c}}}{jln}}{{{b{c}}{f{cAh}}Aj}{{b{c}}}{jln}}{Ah{{An{Al}}}}{d{{An{Al}}}}{A`{{An{Al}}}}{B`{{An{Al}}}}{Bb{{An{Al}}}}{Bd{{An{Al}}}}{ce{}{}}000000000000000000000000000{{{b{c}}}{{Bf{c}}}{jln}}{B`B`}{hh}{BbBb}{AbAb}{BhBh}{AfAf}{BdBd}{AjAj}{BjBj}{{ce}Bl{}{}}00000000{dBn}{A`C`}{B`Bn}{BbC`}``{{{Bf{c}}BjCb}{{Cd{c}}}{jln}}{{}{{b{c}}}{jln}}{Cfc{}}000000000000000000000000000{CfBl}0000000000000`{AdAl}{BhAl}{{ChCh}Cj}{{B`Cl}Cn}{{hCl}Cn}{{BbCl}Cn}{{AbCl}Cn}{{BhCl}Cn}{{AfCl}Cn}{{BdCl}Cn}{{AjCl}Cn}{{BjCl}Cn}{{ChCl}Cn}0{{B`Al}{{D`{Al}}}}{{BbAl}{{D`{Al}}}}{{BhAl}{{D`{Al}}}}{{BdAl}{{D`{Al}}}}{{cAlCj}{{Dd{AlDb}}}{}}000{cc{}}0000000000000{Df{{Dd{AlDh}}}}{B`{{Dd{AlDh}}}}{Bb{{Dd{AlDh}}}}{Bh{{Dd{AlDh}}}}{Bd{{Dd{AlDh}}}}{{Dj{f{DlAl}}}Bl}{{B`{f{DlAl}}}Bl}{{Bb{f{DlAl}}}Bl}{{Bh{f{DlAl}}}Bl}{{Bd{f{DlAl}}}Bl}{AdCf}{BhCf}{{}Cf}0000000000000{ce{}{}}0000000000000`{Df{{Dd{BlDh}}}}{B`{{Dd{BlDh}}}}{Bb{{Dd{BlDh}}}}{Bh{{Dd{BlDh}}}}{Bd{{Dd{BlDh}}}}{{}{{b{c}}}{jln}}{{dhBjCbCf}{{D`{B`}}}}{{CfCfCf}h}{{A`AbBjCbCf}{{D`{Bb}}}}{{CfCf}Ab}{{AdAfBjCbCf}{{D`{Bh}}}}{{CfCf}Af}{{AhAjBjCbCf}{{D`{Bd}}}}{{CfCf}Aj}{{CfDn{An{E`}}}Bj}{AhEb}{BdEb}{ce{}{}}00000000{cDl{}}{c{{Dd{e}}}{}{}}000000000000000000000000000{cEd{}}0000000000000{Df{{Dd{BlDh}}}}{B`{{Dd{BlDh}}}}{Bb{{Dd{BlDh}}}}{Bh{{Dd{BlDh}}}}{Bd{{Dd{BlDh}}}}88888888888888{AhAl}{dAl}{A`Al}{B`Al}{BbAl}{BdAl}","c":[],"p":[[5,"SelectedLayersBuilder",0],[10,"Conv1dLayerLike",0],[5,"HashMap",304],[5,"LoraConv1dConfig",0],[10,"Eq",305],[10,"PartialEq",305],[10,"Hash",306],[10,"Conv2dLayerLike",0],[5,"LoraConv2dConfig",0],[10,"EmbeddingLayerLike",0],[5,"LoraEmbeddingConfig",0],[10,"LinearLayerLike",0],[5,"LoraLinearConfig",0],[5,"Tensor",307],[6,"Option",308],[5,"LoraConv1d",0],[5,"LoraConv2d",0],[5,"LoraLinear",0],[5,"SelectedLayers",0],[5,"LoraEmbedding",0],[5,"LoraConfig",0],[1,"unit"],[5,"Conv1dConfig",309],[5,"Conv2dConfig",309],[8,"VarBuilder",310],[5,"NewLayers",0],[1,"usize"],[6,"MergeError",0],[1,"bool"],[5,"Formatter",311],[8,"Result",311],[8,"Result",312],[6,"Error",312],[6,"Result",313],[10,"Merge",0],[8,"MergeErrorOrError",0],[10,"Saveable",0],[5,"String",314],[1,"f64"],[1,"f32"],[5,"Shape",315],[5,"TypeId",316],[5,"Lora",0]],"b":[[145,"impl-Display-for-MergeError"],[146,"impl-Debug-for-MergeError"]]}],\
["candle_lora_macro",{"doc":"","t":"YX","n":["AutoLoraConvert","replace_layer_fields"],"q":[[0,"candle_lora_macro"]],"d":["",""],"i":[0,0],"f":"``","c":[],"p":[],"b":[]}],\
["candle_lora_transformers",{"doc":"","t":"CCCCCCCCCCCCCCCFFFSFNNNNNNNNNNNNNNNNNNNNONNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNFFNNNNNNNNNNNNNNNONNNNONOOOOONNNNNNNNNNOONNFFFFNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNOONOONNNNONNNNONOOOOOONNNNNNNNNNNNNNNONNNNNFFFNNNNNNNNNNNNNNNNNNONNNNNNNNNOONNNONNNOOONNOOONNNNNNNNNNNONNNFNNNNNNNNNNNNNNNHNFFOOONNNNONNNNNNNNONNNNNNNNNOONNONNONOOOOOONNNNNNONONNFFFFFSNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNOONNNNNOONNNNNNNNOOOOOOOOOONNNNNNNNNNNNNNNNNOOOONNNNNNFFNNNNNNNNNNNNNNNNNNNNNNOONNONNONOOOOOONNNNNNNOONNFFNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNHHHHHHHHHHFFNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNFFFNNNNNNNNNNNNNNNNNNNNNNNNNONNNNNNNNNNNNNNNNNNONNNNNNNNNNONNNFNNNNNNNNNNNHNNNNNNNNHHHFFFFNNNNNNNNNNNNHNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNHHNNNNNNNNNNNNNNNNNNNN","n":["bert","bigcode","blip","blip_text","dinov2","falcon","llama","mistral","mpt","resnet","stable_lm","t5","unsync_func","varbuilder_utils","with_tracing","BertLinear","BertModel","Config","DTYPE","LayerNorm","borrow","borrow","borrow","borrow","borrow_mut","borrow_mut","borrow_mut","borrow_mut","clone","clone_into","default","deref","deref","deref","deref","deref_mut","deref_mut","deref_mut","deref_mut","deserialize","device","drop","drop","drop","drop","eq","fmt","fmt","fmt","forward","forward","forward","from","from","from","from","get_lora_model","get_merged_lora_model","get_tensors","init","init","init","init","into","into","into","into","load","new","new","to_owned","try_from","try_from","try_from","try_from","try_into","try_into","try_into","try_into","type_id","type_id","type_id","type_id","vzip","vzip","vzip","vzip","Config","GPTBigCode","borrow","borrow","borrow_mut","borrow_mut","config","deref","deref","deref_mut","deref_mut","drop","drop","fmt","forward","from","from","hidden_size","init","init","into","into","layer_norm_epsilon","load","max_position_embeddings","multi_query","n_inner","num_attention_heads","num_hidden_layers","starcoder","starcoder_1b","starcoder_3b","starcoder_7b","try_from","try_from","try_into","try_into","type_id","type_id","use_cache","vocab_size","vzip","vzip","BlipForConditionalGeneration","Config","VisionConfig","VisionModel","borrow","borrow","borrow","borrow","borrow_mut","borrow_mut","borrow_mut","borrow_mut","clone","clone","clone_into","clone_into","deref","deref","deref","deref","deref_mut","deref_mut","deref_mut","deref_mut","drop","drop","drop","drop","fmt","fmt","fmt","fmt","forward","forward_t","from","from","from","from","hidden_act","hidden_size","image_captioning_large","image_size","image_text_hidden_size","init","init","init","init","intermediate_size","into","into","into","into","layer_norm_eps","new","num_attention_heads","num_hidden_layers","patch_size","projection_dim","projection_dim","text_config","text_decoder","to_owned","to_owned","try_from","try_from","try_from","try_from","try_into","try_into","try_into","try_into","type_id","type_id","type_id","type_id","vision_config","vision_model","vzip","vzip","vzip","vzip","Config","TextLMHeadModel","TextPooler","borrow","borrow","borrow","borrow_mut","borrow_mut","borrow_mut","clone","clone_into","deref","deref","deref","deref_mut","deref_mut","deref_mut","deserialize","drop","drop","drop","encoder_hidden_size","fmt","fmt","fmt","forward","forward","forward_t","from","from","from","hidden_act","hidden_size","init","init","init","intermediate_size","into","into","into","is_decoder","layer_norm_eps","max_position_embeddings","new","new","num_attention_heads","num_hidden_layers","projection_dim","reset_kv_cache","to_owned","try_from","try_from","try_from","try_into","try_into","try_into","type_id","type_id","type_id","vocab_size","vzip","vzip","vzip","DinoVisionTransformer","borrow","borrow_mut","deref","deref_mut","drop","fmt","forward","forward_t","from","init","into","new","try_from","try_into","type_id","vit_small","vzip","Config","Falcon","alibi","attention_dropout","bias","borrow","borrow","borrow_mut","borrow_mut","bos_token_id","config","default","deref","deref","deref_mut","deref_mut","drop","drop","eos_token_id","falcon7b","fmt","fmt","forward","from","from","get_lora_model","get_merged_lora_model","get_tensors","hidden_dropout","hidden_size","init","init","initializer_range","into","into","layer_norm_epsilon","load","multi_query","n_head_kv","new_decoder_architecture","num_attention_heads","num_hidden_layers","parallel_attn","try_from","try_from","try_into","try_into","type_id","type_id","use_cache","validate","vocab_size","vzip","vzip","Cache","Config","Llama","LlamaConfig","LlamaLinear","MAX_SEQ_LEN","bias","borrow","borrow","borrow","borrow","borrow","borrow_mut","borrow_mut","borrow_mut","borrow_mut","borrow_mut","clone","clone_into","config_7b_v1","config_7b_v2","deref","deref","deref","deref","deref","deref_mut","deref_mut","deref_mut","deref_mut","deref_mut","deserialize","drop","drop","drop","drop","drop","fmt","forward","forward","forward_t","from","from","from","from","from","get_lora_model","get_lora_model","get_merged_lora_model","get_merged_lora_model","get_tensors","get_tensors","get_tensors","hidden_size","hidden_size","init","init","init","init","init","intermediate_size","intermediate_size","into","into","into","into","into","into_config","load","new","num_attention_heads","num_attention_heads","num_hidden_layers","num_hidden_layers","num_key_value_heads","num_key_value_heads","rms_norm_eps","rms_norm_eps","rope_theta","rope_theta","shape","to_owned","try_from","try_from","try_from","try_from","try_from","try_into","try_into","try_into","try_into","try_into","type_id","type_id","type_id","type_id","type_id","use_flash_attn","use_kv_cache","vocab_size","vocab_size","vzip","vzip","vzip","vzip","vzip","weight","Config","Mistral","borrow","borrow","borrow_mut","borrow_mut","clone","clone_into","config_7b_v0_1","deref","deref","deref_mut","deref_mut","drop","drop","eq","fmt","fmt","forward","from","from","get_lora_model","get_merged_lora_model","get_tensors","hidden_act","hidden_size","init","init","intermediate_size","into","into","max_position_embeddings","new","num_attention_heads","num_hidden_layers","num_key_value_heads","rms_norm_eps","rope_theta","sliding_window","to_owned","try_from","try_from","try_into","try_into","type_id","type_id","use_flash_attn","vocab_size","vzip","vzip","Config","Model","borrow","borrow","borrow_mut","borrow_mut","clone","clone_into","deref","deref","deref_mut","deref_mut","drop","drop","eq","fmt","fmt","forward","from","from","init","init","into","into","is_causal","new","replit_code_v1_5_3b","to_owned","try_from","try_from","try_into","try_into","type_id","type_id","vzip","vzip","resnet101","resnet101_no_final_layer","resnet152","resnet152_no_final_layer","resnet18","resnet18_no_final_layer","resnet34","resnet34_no_final_layer","resnet50","resnet50_no_final_layer","Config","Model","borrow","borrow","borrow_mut","borrow_mut","clone","clone_into","deref","deref","deref_mut","deref_mut","drop","drop","eq","fmt","fmt","forward","from","from","head_dim","init","init","into","into","new","num_kv_groups","rotary_ndims","stablelm_3b_4e1t","to_owned","try_from","try_from","try_into","try_into","type_id","type_id","vzip","vzip","Config","T5EncoderModel","T5ForConditionalGeneration","borrow","borrow","borrow","borrow_mut","borrow_mut","borrow_mut","clear_kv_cache","clear_kv_cache","clone","clone_into","decode","default","deref","deref","deref","deref_mut","deref_mut","deref_mut","deserialize","device","device","drop","drop","drop","encode","eos_token_id","eq","fmt","fmt","fmt","forward","forward","from","from","from","init","init","init","into","into","into","load","load","musicgen_small","pad_token_id","to_owned","try_from","try_from","try_from","try_into","try_into","try_into","type_id","type_id","type_id","use_cache","vzip","vzip","vzip","UnsyncFunc","borrow","borrow_mut","clone","clone_into","deref","deref_mut","drop","fmt","forward","forward_t","from","func","init","into","new","to_owned","try_from","try_into","type_id","vzip","from_mmaped_safetensors","from_npz_tensors","from_pth_tensors","QMatMul","TracedLoraConv2d","TracedLoraEmbedding","TracedLoraLinear","borrow","borrow","borrow","borrow","borrow_mut","borrow_mut","borrow_mut","borrow_mut","clone","clone","clone_into","clone_into","conv2d","deref","deref","deref","deref","deref_mut","deref_mut","deref_mut","deref_mut","drop","drop","drop","drop","embeddings","fmt","fmt","fmt","fmt","forward","forward","forward","forward","forward_t","forward_t","forward_t","forward_t","from","from","from","from","from_weights","get_lora_model","get_lora_model","get_merged_lora_model","get_merged_lora_model","get_tensors","get_tensors","init","init","init","init","into","into","into","into","linear","linear_no_bias","new","new","to_owned","to_owned","try_from","try_from","try_from","try_from","try_into","try_into","try_into","try_into","type_id","type_id","type_id","type_id","vzip","vzip","vzip","vzip"],"q":[[0,"candle_lora_transformers"],[15,"candle_lora_transformers::bert"],[87,"candle_lora_transformers::bigcode"],[130,"candle_lora_transformers::blip"],[211,"candle_lora_transformers::blip_text"],[274,"candle_lora_transformers::dinov2"],[292,"candle_lora_transformers::falcon"],[346,"candle_lora_transformers::llama"],[453,"candle_lora_transformers::mistral"],[503,"candle_lora_transformers::mpt"],[539,"candle_lora_transformers::resnet"],[549,"candle_lora_transformers::stable_lm"],[587,"candle_lora_transformers::t5"],[649,"candle_lora_transformers::unsync_func"],[670,"candle_lora_transformers::varbuilder_utils"],[673,"candle_lora_transformers::with_tracing"],[756,"core::result"],[757,"serde::de"],[758,"core::fmt"],[759,"core::fmt"],[760,"candle_core::error"],[761,"candle_lora"],[762,"candle_nn::var_builder"],[763,"candle_lora::loralinear"],[764,"core::option"],[765,"candle_lora::loraconv1d"],[766,"candle_lora::loraconv2d"],[767,"candle_lora::loraembed"],[768,"alloc::string"],[769,"std::collections::hash::map"],[770,"core::any"],[771,"candle_core::error"],[772,"candle_core::device"],[773,"candle_core::shape"],[774,"core::ops::function"],[775,"candle_nn::var_builder"],[776,"candle_nn::var_builder"],[777,"core::convert"],[778,"candle_nn::conv"],[779,"candle_transformers::quantized_var_builder"]],"d":["The BERT model.","The StarCoder model.","The BLIP model.","","The DINOv2 model.","The Falcon model.","The LLama2 model.","Mistral LLM, https://github.com/mistralai/mistral-src","MPT model used by replit-code-v1_5-3b …","ResNet implementation.","The StableLM model.","T5 Text Model …","Layers defined by closures, but not Sync.","Utilities for creating a VarBuilder from a VarMap loaded …","Tracing layers.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Returns the argument unchanged.","Returns the argument unchanged.","Returns the argument unchanged.","Returns the argument unchanged.","Be sure to provide a configuration for each type!","Be sure to provide a configuration for each type!","","","","","","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Returns the argument unchanged.","Returns the argument unchanged.","","","","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Returns the argument unchanged.","Returns the argument unchanged.","Returns the argument unchanged.","Returns the argument unchanged.","","","","","","","","","","","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Returns the argument unchanged.","Returns the argument unchanged.","Returns the argument unchanged.","","","","","","","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Returns the argument unchanged.","","Calls <code>U::from(self)</code>.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Returns the argument unchanged.","Returns the argument unchanged.","Be sure to provide a configuration for each type!","Be sure to provide a configuration for each type!","","","","","","","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","","Load a Falcon model which will be converted to a LoRA …","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Returns the argument unchanged.","Returns the argument unchanged.","Returns the argument unchanged.","Returns the argument unchanged.","Returns the argument unchanged.","Be sure to provide a configuration for each type!","Be sure to provide a configuration for each type!","Be sure to provide a configuration for each type!","Be sure to provide a configuration for each type!","","","","","","","","","","","","","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","","Load a Mistral model which will be converted to a LoRA …","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Returns the argument unchanged.","Returns the argument unchanged.","Be sure to provide a configuration for each type!","Be sure to provide a configuration for each type!","","","","","","","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","","Load a Llama model which will be converted to a LoRA model.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Returns the argument unchanged.","Returns the argument unchanged.","","","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","","","","","","","","","","","","","","","","","Creates a ResNet-18 model.","","Creates a ResNet-34 model.","","","","","","","","","","","","","","","","","","","","","","Returns the argument unchanged.","Returns the argument unchanged.","","","","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Returns the argument unchanged.","Returns the argument unchanged.","Returns the argument unchanged.","","","","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","","","","","","","","","","","","","","","","","","","A layer defined by a simple closure.","","","","","","","","","","","Returns the argument unchanged.","","","Calls <code>U::from(self)</code>.","","","","","","","Load tensors into a VarBuilder backed by a VarMap using …","Load tensors into a VarBuilder backed by a VarMap using …","Load tensors into a VarBuilder backed by a VarMap using …","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","Returns the argument unchanged.","Returns the argument unchanged.","Returns the argument unchanged.","Returns the argument unchanged.","","Be sure to provide a configuration for each type!","Be sure to provide a configuration for each type!","Be sure to provide a configuration for each type!","Be sure to provide a configuration for each type!","","","","","","","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","Calls <code>U::from(self)</code>.","","","","","","","","","","","","","","","","","","","","","",""],"i":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,11,7,10,1,11,7,10,1,1,1,1,11,7,10,1,11,7,10,1,1,11,11,7,10,1,1,7,10,1,11,7,10,11,7,10,1,7,7,7,11,7,10,1,11,7,10,1,11,7,10,1,11,7,10,1,11,7,10,1,11,7,10,1,11,7,10,1,0,0,25,26,25,26,25,25,26,25,26,25,26,26,25,25,26,26,25,26,25,26,26,25,26,26,26,26,26,26,26,26,26,25,26,25,26,25,26,26,26,25,26,0,0,0,0,27,28,29,30,27,28,29,30,27,28,27,28,27,28,29,30,27,28,29,30,27,28,29,30,27,28,29,30,29,29,27,28,29,30,27,27,28,27,28,27,28,29,30,27,27,28,29,30,27,30,27,27,27,27,28,28,30,27,28,27,28,29,30,27,28,29,30,27,28,29,30,28,30,27,28,29,30,0,0,0,33,34,32,33,34,32,33,33,33,34,32,33,34,32,33,33,34,32,33,33,34,32,34,32,34,33,34,32,33,33,33,34,32,33,33,34,32,33,33,33,34,32,33,33,33,32,33,33,34,32,33,34,32,33,34,32,33,33,34,32,0,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,0,35,0,0,37,37,37,37,36,37,36,37,36,37,37,36,37,36,37,36,37,37,37,36,36,37,36,36,36,36,37,37,37,36,37,37,36,37,36,37,37,37,37,37,37,37,36,37,36,37,36,37,37,37,37,36,0,0,0,0,0,0,38,40,41,38,39,42,40,41,38,39,42,39,39,40,40,40,41,38,39,42,40,41,38,39,42,41,40,41,38,39,42,38,38,42,38,40,41,38,39,42,38,42,38,42,38,38,42,40,41,40,41,38,39,42,40,41,40,41,38,39,42,41,42,39,40,41,40,41,40,41,40,41,40,41,38,39,40,41,38,39,42,40,41,38,39,42,40,41,38,39,42,40,39,40,41,40,41,38,39,42,38,0,0,46,47,46,47,46,46,46,46,47,46,47,46,47,46,46,47,47,46,47,47,47,47,46,46,46,47,46,46,47,46,47,46,46,46,46,46,46,46,46,47,46,47,46,47,46,46,46,47,0,0,48,49,48,49,48,48,48,49,48,49,48,49,48,48,49,49,48,49,48,49,48,49,48,49,48,48,48,49,48,49,48,49,48,49,0,0,0,0,0,0,0,0,0,0,0,0,51,52,51,52,51,51,51,52,51,52,51,52,51,51,52,52,51,52,51,51,52,51,52,52,51,51,51,51,51,52,51,52,51,52,51,52,0,0,0,55,53,54,55,53,54,53,54,55,55,54,55,55,53,54,55,53,54,55,53,54,55,53,54,54,55,55,55,53,54,53,54,55,53,54,55,53,54,55,53,54,53,54,55,55,55,55,53,54,55,53,54,55,53,54,55,55,53,54,0,50,50,50,50,50,50,50,50,50,50,50,0,50,50,50,50,50,50,50,50,0,0,0,0,0,0,0,67,68,64,65,67,68,64,65,64,65,64,65,0,67,68,64,65,67,68,64,65,67,68,64,65,67,67,68,64,65,67,68,64,65,67,68,64,65,67,68,64,65,68,67,68,67,68,67,68,67,68,64,65,67,68,64,65,0,0,67,65,64,65,67,68,64,65,67,68,64,65,67,68,64,65,67,68,64,65],"f":"````````````````````{ce{}{}}0000000{bb}{{ce}d{}{}}{{}b}{fc{}}0000000{c{{h{b}}}j}`{fd}000{{bb}l}{{nA`}Ab}{{AdA`}Ab}{{bA`}Ab}{{AfAhAh}{{Aj{Ah}}}}{{nAh}{{Aj{Ah}}}}{{AdAh}{{Aj{Ah}}}}{cc{}}000{{nAlAn{Bb{B`}}{Bb{Bd}}{Bb{Bf}}{Bb{Bh}}}d}0{n{{Bl{BjAh}}}}{{}f}000{ce{}{}}000{{AnblAl}{{Aj{Af}}}}{{AnAh{Bb{Ah}}lAl}n}{{AhAhBn}Ad}3{c{{h{e}}}{}{}}0000000{cC`{}}0005555``5555{CbCd}{fc{}}000{fd}0{{CdA`}Ab}{{CbAhf}{{Aj{Ah}}}}>>`;;::`{{AnCdlAl}{{Aj{Cb}}}}`````{{}Cd}000888877``<<````<<<<<<<<{CfCf}{ChCh}{{ce}d{}{}}0888888887777{{CfA`}Ab}{{ChA`}Ab}{{CjA`}Ab}{{ClA`}Ab}{{CjAh}{{Aj{Ah}}}}{{cAhl}{{h{AhCn}}}{}}{cc{}}000``{{}Ch}``{{}f}000`{ce{}{}}000`{{ChAnlAl}{{Aj{Cl}}}}``````{ClD`}22{c{{h{e}}}{}{}}0000000{cC`{}}000`{ClCj}5555```555555{DbDb}{{ce}d{}{}}{fc{}}00000{c{{h{Db}}}j}{fd}00`{{DbA`}Ab}{{DdA`}Ab}{{D`A`}Ab}{{DdAh}{{Aj{Ah}}}}{{D`AhAh}{{Aj{Ah}}}}{{cAhl}{{h{AhCn}}}{}}{cc{}}00``{{}f}00`{ce{}{}}00```{{DbAnlAl}{{Aj{Dd}}}}{{DbAnlAl}{{Aj{D`}}}}```{D`d}3{c{{h{e}}}{}{}}00000{cC`{}}00`555`55{fc{}}0?{{DfA`}Ab}{{DfAh}{{Aj{Ah}}}};:98{{AnffflAl}{{Aj{Df}}}}554{{AnlAl}{{Aj{Df}}}}:`````::::`{DhDj}{{}Dj}6666{fd}0`1{{DjA`}Ab}{{DhA`}Ab}{{DhAh}{{Aj{Ah}}}}{cc{}}0{{DhAlAn{Bb{B`}}{Bb{Bd}}{Bb{Bf}}{Bb{Bh}}}d}0{Dh{{Bl{BjAh}}}}``{{}f}0`{ce{}{}}0`{{AnDjlAlB`Bh}{{Aj{Dh}}}}``````{c{{h{e}}}{}{}}000{cC`{}}0`{Dj{{Aj{d}}}}`44``````{Dl{{Bb{Ah}}}}5555555555{DnDn}{{ce}d{}{}}{lE`}0{fc{}}000000000{c{{h{Eb}}}j}{fd}0000{{DlA`}Ab}{{DlAh}{{Aj{Ah}}}}{{EdAhf}{{Aj{Ah}}}}{{cAhl}{{h{AhCn}}}{}}{cc{}}0000{{DlAlAn{Bb{B`}}{Bb{Bd}}{Bb{Bf}}{Bb{Bh}}}d}{{EdAlAn{Bb{B`}}{Bb{Bd}}{Bb{Bf}}{Bb{Bh}}}d}10{Dl{{Bl{BjAh}}}}{{Dl{Bl{BjAh}}}d}{Ed{{Bl{BjAh}}}}``{{}f}0000``{ce{}{}}0000{{Ebl}E`}{{AnDnE`lAlB`Bh}{{Aj{Ed}}}}{{lEfE`Eh}{{Aj{Dn}}}}``````````{DlEj}4{c{{h{e}}}{}{}}000000000{cC`{}}0000````66666{DlAh}``7777{ElEl}{{ce}d{}{}}{lEl}{fc{}}000{fd}0{{ElEl}l}{{ElA`}Ab}{{EnA`}Ab}{{EnAhf}{{Aj{Ah}}}}{cc{}}0{{EnAlAn{Bb{B`}}{Bb{Bd}}{Bb{Bf}}{Bb{Bh}}}d}0{En{{Bl{BjAh}}}}``{{}f}0`{ce{}{}}0`{{ElAnlAl}{{Aj{En}}}}``````1{c{{h{e}}}{}{}}000{cC`{}}0``33``3333{F`F`}{{ce}d{}{}}????>>{{F`F`}l}{{F`A`}Ab}{{FbA`}Ab}{{FbAh}{{Aj{Ah}}}}==::99{F`l}{{F`AnlAl}{{Aj{Fb}}}}{{}F`}<::::99<<{{fAnlAl}{{Aj{Fd}}}}{{AnlAl}{{Aj{Fd}}}}10101010``>>>>{FfFf}:{fc{}}000{fd}0{{FfFf}l}{{FfA`}Ab}{{FhA`}Ab}{{FhAhf}{{Aj{Ah}}}}{cc{}}0{Fff}{{}f}0{ce{}{}}0{{FfAnlAl}{{Aj{Fh}}}}33{lFf}2{c{{h{e}}}{}{}}000{cC`{}}044```444444{Fjd}{Fld}{FnFn}{{ce}d{}{}}{{FlAhAh}{{Aj{Ah}}}}{{}Fn}{fc{}}00000{c{{h{Fn}}}j}{FjEh}{FlEh}{fd}00{{FlAh}{{Aj{Ah}}}}`{{FnFn}l}{{FnA`}Ab}{{FjA`}Ab}{{FlA`}Ab}{{FjAh}{{Aj{Ah}}}}<{cc{}}00{{}f}00{ce{}{}}00{{AnFnlAl}{{Aj{Fj}}}}{{AnFnlAl}{{Aj{Fl}}}}{{}Fn}`3{c{{h{e}}}{}{}}00000{cC`{}}00`555`55{FdFd}{{ce}d{}{}}{fc{}}0{fd}{{FdA`}Ab}{{FdAh}{{Aj{Ah}}}}{{cAhl}{{h{AhCn}}}{}}>{cFd{{Gb{Ah}{{G`{{Aj{Ah}}}}}}}}>=0=998={{{Gd{c}}EfEhl}{{h{{Gj{{Gh{Gf}}}}Cn}}}{{Gn{Gl}}}}{{cEfEhl}{{h{{Gj{{Gh{Gf}}}}Cn}}}{{Gn{Gl}}}}0````????????{H`H`}{HbHb}::{{fffHdAn}{{Aj{H`}}}}::::::::9999{HfAh}{{HfA`}Ab}{{HhA`}Ab}{{H`A`}Ab}{{HbA`}Ab}{{HfAh}{{Aj{Ah}}}}{{HhAh}{{Aj{Ah}}}}{{H`Ah}{{Aj{Ah}}}}{{HbAh}{{Aj{Ah}}}}????{cc{}}000{{Ah{Bb{Ah}}AnlAl}Hh}{{HfAlAn{Bb{B`}}{Bb{Bd}}{Bb{Bf}}{Bb{Bh}}}d}{{HhAlAn{Bb{B`}}{Bb{Bd}}{Bb{Bf}}{Bb{Bh}}}d}10{Hf{{Bl{BjAh}}}}{Hh{{Bl{BjAh}}}}{{}f}000{ce{}{}}000{{ffAnlAl}{{Aj{Hh}}}}0{{ffAnlAl}{{Aj{Hf}}}}{{ffHj}{{Aj{Hb}}}}33{c{{h{e}}}{}{}}0000000{cC`{}}0005555","c":[],"p":[[5,"Config",15],[1,"unit"],[1,"usize"],[6,"Result",756],[10,"Deserializer",757],[1,"bool"],[5,"BertLinear",15],[5,"Formatter",758],[8,"Result",758],[5,"LayerNorm",15],[5,"BertModel",15],[5,"Tensor",759],[8,"Result",760],[5,"LoraConfig",761],[8,"VarBuilder",762],[5,"LoraLinearConfig",763],[6,"Option",764],[5,"LoraConv1dConfig",765],[5,"LoraConv2dConfig",766],[5,"LoraEmbeddingConfig",767],[5,"String",768],[5,"HashMap",769],[1,"f64"],[5,"TypeId",770],[5,"GPTBigCode",87],[5,"Config",87],[5,"VisionConfig",130],[5,"Config",130],[5,"VisionModel",130],[5,"BlipForConditionalGeneration",130],[6,"Error",760],[5,"TextLMHeadModel",211],[5,"Config",211],[5,"TextPooler",211],[5,"DinoVisionTransformer",274],[5,"Falcon",292],[5,"Config",292],[5,"LlamaLinear",346],[5,"Cache",346],[5,"Config",346],[5,"LlamaConfig",346],[5,"Llama",346],[6,"DType",771],[6,"Device",772],[5,"Shape",773],[5,"Config",453],[5,"Mistral",453],[5,"Config",503],[5,"Model",503],[5,"UnsyncFunc",649],[5,"Config",549],[5,"Model",549],[5,"T5EncoderModel",587],[5,"T5ForConditionalGeneration",587],[5,"Config",587],[17,"Output"],[10,"Fn",774],[1,"slice"],[10,"SimpleBackend",762],[5,"Box",775],[5,"VarBuilderArgs",762],[5,"Path",776],[10,"AsRef",777],[5,"TracedLoraConv2d",673],[5,"QMatMul",673],[5,"Conv2dConfig",778],[5,"TracedLoraEmbedding",673],[5,"TracedLoraLinear",673],[5,"VarBuilder",779]],"b":[[396,"impl-LlamaLinear"],[397,"impl-Saveable-for-LlamaLinear"]]}]\
]'));
if (typeof exports !== 'undefined') exports.searchIndex = searchIndex;
else if (window.initSearch) window.initSearch(searchIndex);
